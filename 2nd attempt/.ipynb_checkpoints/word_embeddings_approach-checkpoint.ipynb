{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json_lines\n",
    "from langdetect import detect_langs\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "LIMIT_INPUT_ROWS= 10\n",
    "MIN_ENGLISH= 0.0\n",
    "WNL = WordNetLemmatizer()\n",
    "REMOVEABLE_CHARS= '[^A-Za-z ]'\n",
    "ALL_TAGS= ['CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PDT',\n",
    " 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP',\n",
    " 'WP$', 'WRB']\n",
    "ACCEPTABLE_TAGS= ['CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PDT',\n",
    " 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP',\n",
    " 'WP$', 'WRB']\n",
    "MIN_WORD_OCCURRENCES= 5\n",
    "\n",
    "number_entries= 0\n",
    "with open ('reviews.json', 'rb') as f:\n",
    "    for item in json_lines.reader(f):\n",
    "        number_entries+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN INFO\n",
    "reviews= []; polarity= []; are_early= []\n",
    "included_indexs= []\n",
    "j= 0\n",
    "while j < LIMIT_INPUT_ROWS:\n",
    "    randint= random.randint(0, number_entries-1)\n",
    "    if not randint in included_indexs:\n",
    "        included_indexs.append(randint)\n",
    "        j+= 1\n",
    "    \n",
    "with open('reviews.json', 'rb') as f: # 5,000 entries in reviews.json\n",
    "    for counter, item in enumerate(json_lines.reader(f)):\n",
    "        if counter in included_indexs:\n",
    "            reviews.append(item['text'])\n",
    "            polarity.append(item['voted_up'])\n",
    "            are_early.append(item['early_access'])\n",
    "\n",
    "# END PRODUCTS: reviews, polarity, are_early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love all the CIV strat games.  Very pollished and challenging gaming experience.  Love the hugh maps and marathon gaming - strat heads will love it!', 'Jogo interessante, mais voltado a quem gosta do gÃªnero de combate com cartas.', 'Great game, high replayability... One of those games that just get better and better the more you play it', 'its sicc', 'Nice', 'not addictive', 'nehrajte to blbost.', '(Review text hidden)', 'Na wstÄ™pie:     WidaÄ‡ to juÅ¼ nawet na screenach, ale   odczuwa siÄ™   Po pierwszych 30 minutach grania miaÅ‚em wraÅ¼enie, Å¼e gra ta       - prosta melodyjka w tle i nic wiÄ™cej - chciaÅ‚oby siÄ™ nawet rzec, Å¼e  , gdyby nie fakt, Å¼e    CaÅ‚a   opiera siÄ™ na wybraniu kraju, ktÃ³ry chcemy poprowadziÄ‡ do zwyciÄ™stwa   oraz wybraniu rodzaju rzÄ…dÃ³w w naszym kraju   i zajmowaniu kolejnych fragmentÃ³w lÄ…du, dopÃ³ki caÅ‚y Å›wiat nie bÄ™dzie nasz. Jak juÅ¼ wspomniaÅ‚em gra   do dalszej gry, a   (przynajmniej dla ludzi co uÅ¼ywajÄ… monitorÃ³w Full HD)   Dodatkowo trzeba nadmieniÄ‡, Å¼e   na wiele jÄ™zykÃ³w Å›wiata,   w tym celu  , wiÄ™c samo', 'Bir oyuna bu kadar kasmaya ne gerek var anlamÄ±yorum ya, boÅŸ iÅŸ.']\n",
      "########################################################################\n",
      "['I love all the CIV strat games  Very pollished and challenging gaming experience  Love the hugh maps and marathon gaming  strat heads will love it', 'Jogo interessante mais voltado a quem gosta do gnero de combate com cartas', 'Great game high replayability One of those games that just get better and better the more you play it', 'its sicc', 'Nice', 'not addictive', 'nehrajte to blbost', 'Review text hidden', 'Na wstpie     Wida to ju nawet na screenach ale   odczuwa si   Po pierwszych  minutach grania miaem wraenie e gra ta        prosta melodyjka w tle i nic wicej  chciaoby si nawet rzec e   gdyby nie fakt e    Caa   opiera si na wybraniu kraju ktry chcemy poprowadzi do zwycistwa   oraz wybraniu rodzaju rzdw w naszym kraju   i zajmowaniu kolejnych fragmentw ldu dopki cay wiat nie bdzie nasz Jak ju wspomniaem gra   do dalszej gry a   przynajmniej dla ludzi co uywaj monitorw Full HD   Dodatkowo trzeba nadmieni e   na wiele jzykw wiata   w tym celu   wic samo', 'Bir oyuna bu kadar kasmaya ne gerek var anlamyorum ya bo i']\n"
     ]
    }
   ],
   "source": [
    "# FILTER OUT SPECIFIC CHARS\n",
    "\n",
    "import re\n",
    "new_reviews= []\n",
    "for i, text in enumerate(reviews):\n",
    "    text= re.sub(REMOVEABLE_CHARS, '', text)\n",
    "    new_reviews.append(text)\n",
    "# print(reviews)\n",
    "# print(\"########################################################################\")\n",
    "# print(new_reviews)\n",
    "reviews= new_reviews\n",
    "\n",
    "# END PRODUCTS: reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love all the CIV strat games  Very pollished and challenging gaming experience  Love the hugh maps and marathon gaming  strat heads will love it', 'Great game high replayability One of those games that just get better and better the more you play it', 'not addictive']\n"
     ]
    }
   ],
   "source": [
    "# FILTER TEXT BY LANGUAGE\n",
    "\n",
    "filtered_reviews= []\n",
    "filtered_polarity= []\n",
    "filtered_are_early= []\n",
    "for i, text in enumerate(reviews):\n",
    "    try:\n",
    "        langs = detect_langs(text)\n",
    "    except:\n",
    "        print(\"ERROR: langs failed to define itself. Happens occassionally - just rerun\")\n",
    "        pass\n",
    "    for lang in langs:\n",
    "        if str(lang)[0:2] == 'en':\n",
    "            if float(str(lang)[3:]) > MIN_ENGLISH:\n",
    "                filtered_reviews.append(reviews[i])\n",
    "                filtered_polarity.append(polarity[i])\n",
    "                filtered_are_early.append(are_early[i])\n",
    "reviews= filtered_reviews\n",
    "polarity= filtered_polarity\n",
    "are_early= filtered_are_early\n",
    "\n",
    "#print(reviews)\n",
    "# END PRODUCTS: reviews, polarity, are_early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love all the CIV strat game Very pollished and challenging gaming experience Love the hugh map and marathon gaming strat head will love it', 'Great game high replayability One of those game that just get better and better the more you play it', 'not addictive']\n"
     ]
    }
   ],
   "source": [
    "# FILTER TEXT BY WORD TYPE\n",
    "\n",
    "#print(reviews)\n",
    "filtered_reviews= []\n",
    "for i, text in enumerate(reviews):\n",
    "    #print(\"-------------------------------------\")\n",
    "    new_text= []\n",
    "    split_text= text.split()\n",
    "    tags= nltk.pos_tag(split_text)\n",
    "    #print(tags)\n",
    "    #print(\"#############\")\n",
    "    lemd_split_text= []\n",
    "    for word in split_text:\n",
    "        lemd_split_text.append(WNL.lemmatize(word))\n",
    "    tags= nltk.pos_tag(lemd_split_text)\n",
    "    #print(tags)\n",
    "    for j, word in enumerate(lemd_split_text):\n",
    "        if tags[j][1] in ACCEPTABLE_TAGS:\n",
    "            new_text.append(word)\n",
    "    filtered_reviews.append(new_text)\n",
    "reviews= [' '.join([str(elem) for elem in sublist]) for sublist in filtered_reviews]\n",
    "print(reviews)\n",
    "\n",
    "# END PRODUCTS: reviews, polarity, are_early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET REVIEWS AS LIST OF LISTS\n",
    "\n",
    "no_sentences= 0\n",
    "reviews_as_ll= [] # ll denoting the list of list data\n",
    "for text in reviews:\n",
    "    split_text= text.split()\n",
    "    reviews_as_ll.append(split_text)\n",
    "    no_sentences+= 1\n",
    "\n",
    "# END PRODUCTS: ll_reviews, no_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(reviews_as_ll, polarity, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-5faf5a63b440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMIN_WORD_OCCURRENCES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_as_ll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_as_ll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# can be a non-repeatable, 1-pass generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_training_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[0;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# should be set by `build_vocab`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must first build vocabulary before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must initialize vectors before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "model= gensim.models.Word2Vec(min_count= MIN_WORD_OCCURRENCES)\n",
    "model.build_vocab(reviews_as_ll)\n",
    "model.train(reviews_as_ll, total_examples=no_sentences, epochs=model.epochs)  # can be a non-repeatable, 1-pass generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('are', 0.4341857433319092), ('to', 0.41584882140159607), ('you', 0.41312918066978455), ('of', 0.3936181664466858), ('and', 0.3795650899410248), ('a', 0.3577914834022522), ('but', 0.3577427864074707), ('that', 0.3477071523666382), ('at', 0.34456679224967957), ('-There', 0.3431721031665802)]\n"
     ]
    }
   ],
   "source": [
    "#model['gear']  # raw NumPy vector of a word\n",
    "sims= model.wv.most_similar('the', topn=10)  # get other similar words\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
